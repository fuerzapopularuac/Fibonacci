import tensorflow as tf
import numpy as np

# =========================
# GENERAR FIBONACCI
# =========================
fib = [1, 1]
for _ in range(50):
    fib.append(fib[-1] + fib[-2])

# log transform
fib_log = np.log(fib)

# Dataset
X = []
y = []
for i in range(2, len(fib_log)):
    X.append([fib_log[i-2], fib_log[i-1]])
    y.append([fib_log[i]])

X = np.array(X, dtype=np.float32)
y = np.array(y, dtype=np.float32)

# =========================
# RED NEURONAL
# =========================
W1 = tf.Variable(tf.random.normal([2, 64]))
b1 = tf.Variable(tf.zeros([64]))

W2 = tf.Variable(tf.random.normal([64, 1]))
b2 = tf.Variable(tf.zeros([1]))

def model(x):
    h = tf.nn.relu(tf.matmul(x, W1) + b1)
    return tf.matmul(h, W2) + b2

def loss(y_true, y_pred):
    return tf.reduce_mean(tf.square(y_true - y_pred))

optimizer = tf.optimizers.Adam(0.005)

# =========================
# ENTRENAMIENTO
# =========================
for epoch in range(3000):
    with tf.GradientTape() as tape:
        pred = model(X)
        l = loss(y, pred)

    grads = tape.gradient(l, [W1, b1, W2, b2])
    optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2]))

    if epoch % 500 == 0:
        print(f"Epoch {epoch} - Loss: {l.numpy():.6f}")

print("\nIA entrenada\n")

# =========================
# SIMULADOR
# =========================
a = float(input("Primer Fibonacci: "))
b = float(input("Segundo Fibonacci: "))

a_log = np.log(a)
b_log = np.log(b)

print("\nSecuencia generada:\n")
for _ in range(5):
    x = np.array([[a_log, b_log]], dtype=np.float32)
    pred_log = model(x).numpy()[0][0]
    pred = np.exp(pred_log)

    print(int(pred))
    a_log, b_log = b_log, pred_log

